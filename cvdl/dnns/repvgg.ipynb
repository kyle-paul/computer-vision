{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RepVGG\n",
    "\n",
    "<img src=\"https://i.ibb.co/wrxq7Kv/image.png\" alt=\"image\" border=\"0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reparameterization\n",
    "\n",
    "Chứng minh kỹ thuật reparameterization, gọi đầu vào hình ảnh $X \\in \\mathbb{R}^{n \\times n}$ là một ma trận có dạng:\n",
    "\n",
    "$$ X = \n",
    "\\begin{pmatrix}\n",
    "x_{11} & x_{12} & x_{13} & x_{14} & x_{15} \\\\\n",
    "x_{21} & x_{22} & x_{23} & x_{24} & x_{25} \\\\ \n",
    "x_{31} & x_{32} & x_{33} & x_{34} & x_{35} \\\\\n",
    "x_{41} & x_{42} & x_{44} & x_{44} & x_{45} \\\\\n",
    "x_{51} & x_{52} & x_{55} & x_{55} & x_{55} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "và ma trận trọng số $W$ thực hiện convolution:\n",
    "\n",
    "$$ W = \n",
    "\\begin{pmatrix}\n",
    "w_{11} & w_{12} & w_{13} \\\\\n",
    "w_{21} & w_{22} & w_{23} \\\\\n",
    "w_{31} & w_{32} & w_{33} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Gọi ma trận kết quả sau khi thực hiện phép convolution (padding=$1$) $X * W$ là $Y$:\n",
    "\n",
    "$$ Y =\n",
    "\\begin{pmatrix}\n",
    "y_{11} & y_{12} & y_{13} & y_{14} & y_{15} \\\\\n",
    "y_{21} & y_{22} & y_{23} & y_{24} & y_{25} \\\\ \n",
    "y_{31} & y_{32} & y_{33} & y_{34} & y_{35} \\\\\n",
    "y_{41} & y_{42} & y_{44} & y_{44} & y_{45} \\\\\n",
    "y_{51} & y_{52} & y_{55} & y_{55} & y_{55} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Trong đó $y_{22} = x_{11} \\times w_{11} + x_{12} \\times w_{12} + \\dots + x_{33} \\times w_{33}$\n",
    "\n",
    "Gọi ma trận kết quả sau khi thực hiện phép convolution pointwise với giá trị $p$ là $Z$:\n",
    "$$ Z =\n",
    "\\begin{pmatrix}\n",
    "z_{11} & z_{12} & z_{13} & z_{14} & z_{15} \\\\\n",
    "z_{21} & z_{22} & z_{23} & z_{24} & z_{25} \\\\ \n",
    "z_{31} & z_{32} & z_{33} & z_{34} & z_{35} \\\\\n",
    "z_{41} & z_{42} & z_{44} & z_{44} & z_{45} \\\\\n",
    "z_{51} & z_{52} & z_{55} & z_{55} & z_{55} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Trong đó $z_{22} = x_{22} \\times p$\n",
    "Vậy trong ma trận kết quả $K = Y + Z$ thì vị trí $K_{22} = y_{22} + z_{22} = (x_{11} \\times w_{11} + x_{12} \\times w_{12} + \\dots + x_{33} \\times w_{33}) + (x_{22} \\times p)$\n",
    "\n",
    "\n",
    "Đây là operations diễn ra trong lúc train. Tuy nhiên khi inference thì ta áp dụng kỹ thuật reparameterization để giảm lượng params tính toán hay FLOPS bằng các bước sau:\n",
    "1. Padding giá trị $p$ thành ma trận trọng số $P$ có shape bằng ma trận $W$\n",
    "2. Tạo ma trận trọng số mởi là $E = W + E$\n",
    "3. Thực hiện phép convolution $X * E$ \n",
    "\n",
    "Lúc này ma trận được padded $P$ có dạng\n",
    "$$ P = \n",
    "\\begin{pmatrix}\n",
    "0 & 0 & 0 \\\\\n",
    "0 & p & 0 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Ma trận trọng số mới $E$ có dạng:\n",
    "$$ E = \n",
    "\\begin{pmatrix}\n",
    "w_{11} & w_{12} & w_{13} \\\\\n",
    "w_{21} & w_{22} + p & w_{23} \\\\\n",
    "w_{31} & w_{32} & w_{33} \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Ma trận kết quả $K'$ có thành phần $K'_{22} = x_{11} \\times w_{11} + x_{12} \\times w_{12} + \\dots + (w_{22} + p) \\times x_{22} + \\dots + x_{33} \\times w_{33} $. \\\n",
    "Chú ý phần tử $(w_{22} + p) \\times x_{22} = w_{22} \\times x_{22} + x_{22} \\times p$\n",
    "Từ đây ta dễ dàng so sánh và thấy $K = K'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.4000,  9.3000,  9.9000, 11.2000,  6.7000],\n",
       "         [13.6000, 13.9000, 12.8000, 11.2000,  6.8000],\n",
       "         [17.6000, 14.6000, 12.6000, 13.6000,  6.1000],\n",
       "         [ 9.0000, 15.4000, 19.1000, 15.5000,  8.1000],\n",
       "         [10.6000, 13.8000, 16.9000, 18.9000, 12.6000]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [2, 3, 5, 1, 2],\n",
    "    [9, 8, 1, 5, 4],\n",
    "    [0, 1, 2, 4, 0],\n",
    "    [5, 6, 7, 8, 9],\n",
    "]).unsqueeze(0).to(torch.float32)\n",
    "\n",
    "W = torch.tensor([\n",
    "    [0.5, 0.1, 0.2],\n",
    "    [0.2, 0.3, 0.9],\n",
    "    [0.1, 0.4, 0.6],\n",
    "]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "P = torch.tensor([\n",
    "    [0.7]\n",
    "]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "Y = F.conv2d(X, W, stride=1, padding=1)\n",
    "Z = F.conv2d(X, P, stride=1, padding=0)\n",
    "K = Y + Z\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.4000,  9.3000,  9.9000, 11.2000,  6.7000],\n",
       "         [13.6000, 13.9000, 12.8000, 11.2000,  6.8000],\n",
       "         [17.6000, 14.6000, 12.6000, 13.6000,  6.1000],\n",
       "         [ 9.0000, 15.4000, 19.1000, 15.5000,  8.1000],\n",
       "         [10.6000, 13.8000, 16.9000, 18.9000, 12.6000]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [2, 3, 5, 1, 2],\n",
    "    [9, 8, 1, 5, 4],\n",
    "    [0, 1, 2, 4, 0],\n",
    "    [5, 6, 7, 8, 9],\n",
    "]).unsqueeze(0).to(torch.float32)\n",
    "\n",
    "W = torch.tensor([\n",
    "    [0.5, 0.1, 0.2],\n",
    "    [0.2, 0.3, 0.9],\n",
    "    [0.1, 0.4, 0.6],\n",
    "]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "P = torch.tensor([\n",
    "    [0., 0., 0.],\n",
    "    [0., 0.7, 0.],\n",
    "    [0., 0., 0.],\n",
    "]).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "E = W + P\n",
    "\n",
    "K_ = F.conv2d(X, E, stride=1, padding=1)\n",
    "K_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How BatchNorm works\n",
    "\n",
    "Read more in this paper [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "\n",
    "Cho input $X \\in \\mathbb{R}^{B \\times C \\times H \\times W}$ với $B,C,H,W$ lần lượt là batch size, channels, height, width. Khi đưa qua BatchNorm, thì $\\text{BN}(X)$ được tính bằng cách: \\\n",
    "- Khởi tạo vector $\\mu$ (mean) và $v$ (variance) theo phân phối chuẩn:\n",
    "$$\n",
    "\\mu, v\\in \\mathbb{R}^C \\space | \\space  \\mu_i=0, v_i=1 \\space | \\space \\forall \\mu_i \\in \\mu, \\forall v_i \\in v\n",
    "$$\n",
    "\n",
    "- Sau đó $X$ sẽ được biến đối trong không gian bằng 2 phép $\\text{normalize}$ và $\\text{scale+shift}$\n",
    "\n",
    "$$\n",
    "X_{\\text{norm}} = \\frac{X - \\mu}{\\sqrt{v + \\epsilon}} \\\\\n",
    "X_{\\text{new}} = X_{\\text{norm}} \\gamma + \\beta\n",
    "$$\n",
    "\n",
    "- Trong đó epsilon $\\epsilon$ được khởi tạo $=1e^{-5}$ và $\\gamma, \\beta \\in R^C$ hay là vector shape là $(1, C, 1, 1)$. Hay từng feature $X_{\\text{new}}[:,i:,:]$ trong $X$ được tính:\n",
    "\n",
    "$$\n",
    "X^{\\text{new}}_{[:,i:,:]} =  \\frac{X_{[:,i,:,:]} - \\mu_i}{\\sqrt{v + \\epsilon}} \\gamma + \\beta_i\n",
    "$$\n",
    "\n",
    "## BatchNorm kết hợp Convolution\n",
    "Như ta đã biết, tổ hợp phổ biến trong computer vision là $\\text{Conv-Relu-BatchNorm}$. BatchNorm diễn ra sau Convolution (ví dụ bỏ qua ReLU) thì làm sao ta kết hợp bước Conv-BatchNorm trong lúc inference để tính toán nhanh hơn.  Gọi $X \\in \\mathbb{R}^{B, C_{in}, H, W}$ là ma trận đầu vào $W \\in \\mathbb{W}^{C_{out}, C_{in}, K, K}$ là ma trận trọng số để thực hiện phép convolution và ma trận kết quả là $Y = X * W + b \\space | \\space Y \\in \\mathbb{R}^{B, C_{out}, H', W'}$ với $*$ là phép convolution và $b$ là bias.\n",
    "\n",
    "$$\n",
    "\\text{BN}(Y, \\mu, v, \\gamma, \\beta) = (Y - \\mu) \\frac{\\gamma}{\\sqrt{v + \\epsilon}} + \\beta \\\\\n",
    "= (X * W + b - \\mu) \\frac{\\gamma}{\\sqrt{v + \\epsilon}}. \\\\\n",
    "= X * (W \\frac{\\gamma}{\\sqrt{v + \\epsilon}}) + \\frac{\\gamma}{\\sqrt{v + \\epsilon}} (b - \\mu) + \\beta\n",
    "= X * W' + b'\n",
    "$$\n",
    "\n",
    "Vậy ma trận trọng số mới là $W' = W \\frac{\\gamma}{\\sqrt{v + \\epsilon}}$ và bias mới là $b'= \\frac{\\gamma}{\\sqrt{v + \\epsilon}} (b - \\mu) + \\beta$. \\\\\n",
    "Nhưng ở đây ta cần phải lưu ý thêm về chiều khi nhần vào của $W'_{[i,:,:,:]} = \\frac{\\gamma_i}{\\sqrt{v_i + \\epsilon}} W_{[i,:,:,:]}$. Đây là lý do ta phải reshape các vector $\\gamma, v \\in (1, C_{out}, 1, 1)$ thành $(C_{out}), 1, 1, 1)$ trước khi nhân.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, eps=0, momentum=0.1, training_mode=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.training_mode = training_mode\n",
    "        self.momentum = 0.1\n",
    "        self.eps = eps\n",
    "\n",
    "        # trainable parameters\n",
    "        self.gamma = nn.Parameter(torch.ones(1, num_features, 1, 1))\n",
    "        self.beta = nn.Parameter(torch.zeros(1, num_features, 1, 1))\n",
    "\n",
    "        # running mean & variance\n",
    "        self.r_mean = torch.zeros(1, num_features, 1, 1)\n",
    "        self.r_var = torch.ones(1, num_features, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training_mode:\n",
    "            x_mean = x.mean([0, 2, 3], keepdim=True)\n",
    "            x_var = x.var([0, 2, 3], keepdim=True, unbiased=False)\n",
    "\n",
    "            # Update running mean and variance\n",
    "            self.r_mean = (1 - self.momentum) * self.r_mean + self.momentum * x_mean\n",
    "            self.r_var = (1 - self.momentum) * self.r_var + self.momentum * x_var\n",
    "\n",
    "        else:\n",
    "            x_mean = self.r_mean\n",
    "            x_var = self.r_var\n",
    "\n",
    "        x_norm = (x - x_mean) / torch.sqrt(x_var + self.eps)         # Normalize\n",
    "        x_out = x_norm * self.gamma + self.beta                      # Scale and Shift\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize matrix X, weight W and bias b\n",
    "X = torch.randn(12, 32, 224, 224)\n",
    "W = torch.randn(64, 32, 3, 3)\n",
    "b = torch.randn(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal convolution\n",
    "Y = F.conv2d(X, W, b, stride=1, padding=1)\n",
    "bn = BatchNorm(64)\n",
    "Z = bn(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape before multiplication\n",
    "gamma = bn.gamma.view(64, 1, 1, 1)\n",
    "var = bn.r_var.view(64, 1, 1, 1)\n",
    "mean = bn.r_mean.view(64, 1, 1, 1)\n",
    "beta = bn.beta.view(64, 1, 1, 1)\n",
    "eps = bn.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparameterization\n",
    "W_ = W * (gamma / torch.sqrt(var + eps))\n",
    "b_ = (gamma / torch.sqrt(var + eps)) * (b.view(64, 1, 1, 1) - mean) + beta\n",
    "b_ = b_.squeeze()\n",
    "\n",
    "Z_ = F.conv2d(X, W_, b_, stride=1, padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "print(Z[2,10,56,56])\n",
    "print(Z_[2,10,56,56])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RepVGG Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
